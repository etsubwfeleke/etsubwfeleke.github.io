<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Web Scraping on Etsub Feleke</title>
    <link>https://etsubwfeleke.github.io/categories/web-scraping/</link>
    <description>Recent content in Web Scraping on Etsub Feleke</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Thu, 14 Nov 2024 14:51:06 -0500</lastBuildDate>
    <atom:link href="https://etsubwfeleke.github.io/categories/web-scraping/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Web scraping with Beautiful Soup</title>
      <link>https://etsubwfeleke.github.io/web_scraping/</link>
      <pubDate>Thu, 14 Nov 2024 14:51:06 -0500</pubDate>
      <guid>https://etsubwfeleke.github.io/web_scraping/</guid>
      <description>&lt;h2 id=&#34;exploring-web-scraping-with-beautiful-soup-and-requests-a-learning-journey&#34;&gt;Exploring Web Scraping with Beautiful Soup and Requests: A Learning Journey&lt;/h2&gt;&#xA;&lt;p&gt;Understanding web scraping techniques is essential for data science. The goal was to extract structured data from a real-world website, specifically focusing on the World Economic Forum&amp;rsquo;s Wikipedia page. This hands-on experience allowed me to learn how to programmatically interact with web content and parse HTML to gather information.&lt;/p&gt;&#xA;&lt;h3 id=&#34;the-tools-requests-and-beautiful-soup&#34;&gt;The Tools: Requests and Beautiful Soup&lt;/h3&gt;&#xA;&lt;p&gt;I chose to use two powerful Python libraries for this project: &lt;code&gt;requests&lt;/code&gt; for making HTTP requests to fetch web pages, and &lt;code&gt;BeautifulSoup&lt;/code&gt; for parsing the HTML content.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
